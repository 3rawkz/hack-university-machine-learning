## Syllabus

### Day 1: Getting Started

[Discussion](01-getting-started.md)

[Notebooks](../huml/day1)

### Day 2: [Learning by Experimenting]

[Discussion](02-learning-by-experimenting.md)

[Notebooks](../huml/day2)

### Day 3: [Time Series](03-time-series.md)

### Day 4: [Bots](03-bots.md)

4. Information Theory
    - Entropy
        - Thermodynamics
        - Information
    - Black Holes and an Expanding Universe
5. Supervised Classification
    - Application/Motivation
    - Logistic Regression
        - Derived from Linear Regression
    - Decision Tree
        - Random Forest
    - Neural Nets
    - SVM
    - Genetic Algorithms useful when
        - fit-test is fast
        - thoughtful design is hard
6. Unsupervised Classification
    - Applications/Motivation
    - Clustering
    - KMeans
    - KNN
    - Neural Nets
        - Word2Vec
7. Ensemble Methods
8. Meta-parameter search (tuning your learner)
    - Grid Search
    - Random Search
    - Graph search with heuristic
9. Supervised v Unsupervised
    - Labels
    - Imbalanced Data Sets
10. Bayesian Inference
    - Naive Bayes
    - Non-naive bayes (Markov Models)
11. More Neural Nets
    - Convolutional
    - Recurrent
    - Recursive
    - Deep
    - Examples: image processing
12. Language Models
    - Regular Expressions and Finite State Automata
    - Grammar (Regular, Irregular, etc)
    - Auto-complete (predictive typing)
    - [Spell Checker in 30-lines of code](http://norvig.com/spell-correct.html) (by Norvig)
13. Statistical Models
    - “Big Data” vs “Big Model”
    - Big Data: web search 
    - Big Model: Detecting habitable planets
